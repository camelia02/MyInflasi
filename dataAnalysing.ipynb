{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REQUIRED DEPENDENCIES\n",
    "- pandas\n",
    "- numpy\n",
    "- matplotlib\n",
    "- pyarroq\n",
    "- fastparquet\n",
    "- dask\n",
    "- fuzzywuzzy\n",
    "- ipywidgets\n",
    "- ipython\n",
    "- jupyter_contrib_nbextensions\n",
    "\n",
    "use pip install in terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If not already installed, do: pip install pandas fastparquet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "url_file = 'pricecatcher/pricecatcher/price_urls.json'\n",
    "price_df = []\n",
    "\n",
    "\n",
    "with open(url_file, 'r') as json_file:\n",
    "    price_urls_data = json.load(json_file)\n",
    "\n",
    "for entry in price_urls_data:\n",
    "    parquet_urls = entry['parquet_files']\n",
    "    for url in parquet_urls:\n",
    "        df = pd.read_parquet(url)\n",
    "        price_df.append(df)\n",
    "    \n",
    "URL_LOOKUP = 'https://storage.googleapis.com/dosm-public-pricecatcher/lookup_item.parquet'\n",
    "URL_PREMISE = 'https://storage.googleapis.com/dosm-public-pricecatcher/lookup_premise.parquet'\n",
    "\n",
    "price = pd.concat(price_df, ignore_index=True)\n",
    "premise = pd.read_parquet(URL_PREMISE)\n",
    "lookup = pd.read_parquet(URL_LOOKUP)\n",
    "if 'date' in price.columns: price['date'] = pd.to_datetime(price['date'])\n",
    "if 'date' in lookup.columns: lookup['date'] = pd.to_datetime(lookup['date'])\n",
    "if 'date' in premise.columns: premise['date'] = pd.to_datetime(premise['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOOKUP TABLE TO BE LEFT JOIN WITH PRICE TABLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT JOIN LOOKUP TABLE WITH PRICE TABLE ON ITEM CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items=lookup.merge(price,on='item_code',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT JOIN PREMISE AGAINST PRICE TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "premise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_location = premise.merge(price, on='premise_code',how='left',indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE A MAPPING DICT FROM items_location TABLE WITH  premise_code AS THE KEY AND state AS THE VALUE. UPDATE PREMISE CODE IN items TABLE USING THE MAPPING DICTIONARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_location_dict = premise.set_index('premise_code')['state'].to_dict()\n",
    "items['premise_code'] = items['premise_code'].map(mapping_location_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_dict = lookup.set_index('item')['item_code'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_usage_bytes = items.memory_usage(deep=True).sum()\n",
    "print(f\"Total memory usage of the DataFrame: {memory_usage_bytes / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USE VAEX AND DASK BECAUSE THE DATA TABLE IS TOO BIG AND TAKES TOO LONG TO FILTER THE DATA. CONVERT PANDAS DF TO DASK DF SO I CAN USE DASK PARALLEL PROCESSING.\n",
    "\n",
    "Failed to build vaex-core\n",
    "ERROR: Could not build wheels for vaex-core, which is required to install pyproject.toml-based projects\n",
    "\n",
    "At 2 million data point this algorithm can filter data at an average of 40 seconds.\n",
    "At 44.6 million data points this algorithm can filter data at an average of 720 seconds\n",
    "\n",
    "For 2 million data points:\n",
    "Processing Rate = 2,000,000 / 40 = 50,000 data points per second\n",
    "\n",
    "For 44.6 million data points:\n",
    "Processing Rate = 44,600,000 / 720 = 61,944 data points per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from fuzzywuzzy import fuzz\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(input, choices, threshold=80):\n",
    "        match_score = [(choice, fuzz.partial_ratio(input, choice.lower())) for choice in choices if isinstance(choice, str)]\n",
    "        matched_item = max(match_score, key=lambda x: x[1], default=None)\n",
    "        if matched_item[1] >= threshold:\n",
    "            return matched_item[0]\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "def filter_data(dataframe):\n",
    "    state_input = widgets.Text(description=\"State: \")\n",
    "    item_input = widgets.Text(description=\"Item: \")\n",
    "    submit_button = widgets.Button(description=\"Submit\")\n",
    "    cancel_button = widgets.Button(description=\"Cancel\")\n",
    "    timer = widgets.Label(value=\"Time elapsed: 0 seconds\")\n",
    "    buttons_box = widgets.HBox([submit_button, cancel_button])\n",
    "\n",
    "    display(state_input)\n",
    "    display(item_input)\n",
    "    display(buttons_box)\n",
    "    display(timer)\n",
    "\n",
    "    timer_thread = None\n",
    "    stop_event = threading.Event()\n",
    "\n",
    "    def update_timer(start_time, stop_event):\n",
    "        while True:\n",
    "            if stop_event.is_set():\n",
    "                break\n",
    "            elapsed_time = time.time() - start_time\n",
    "            timer.value = f\"Time elapsed: {elapsed_time: .2f} seconds\"\n",
    "    \n",
    "    def on_submit(button):\n",
    "        global filtered_data\n",
    "        start_time = time.time()\n",
    "        timer_thread = threading.Thread(target=update_timer, args=(start_time, stop_event))\n",
    "        timer_thread.start()\n",
    "        item = item_input.value.strip().lower()\n",
    "        state = state_input.value.strip().lower()\n",
    "\n",
    "        if not item:\n",
    "            print(\"Item must be entered\")\n",
    "            filtered_data = pd.DataFrame()\n",
    "        else:\n",
    "            # Convert pandas DataFrame to Dask DataFrame\n",
    "            df = dd.from_pandas(dataframe, npartitions=8)\n",
    "\n",
    "            # Filter the DataFrame using fuzzy matching\n",
    "            matched_item = match(item, df['item'])\n",
    "            if matched_item:\n",
    "                filtered_data = df[df['item'] == matched_item].compute()\n",
    "                if state:\n",
    "                    matched_state = match(state, df['premise_code'])\n",
    "                    if matched_state:\n",
    "                        item_state = state\n",
    "                        filtered_data = filtered_data[filtered_data['premise_code'] == matched_state]\n",
    "            else:\n",
    "                print(\"No matches found for the provided item.\")\n",
    "                filtered_data = pd.DataFrame()\n",
    "            stop_event.set()\n",
    "            timer_thread.join()\n",
    "            display(filtered_data)\n",
    "    \n",
    "\n",
    "    def on_cancel(button):\n",
    "        global filtered_data\n",
    "        print(\"Action canceled.\")\n",
    "        stop_event.set()\n",
    "        if timer_thread is not None:\n",
    "            timer_thread.join()\n",
    "        filtered_data = pd.DataFrame()\n",
    "\n",
    "    submit_button.on_click(on_submit)\n",
    "    cancel_button.on_click(on_cancel)\n",
    "\n",
    "filter_data(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALYZE FILTERED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "daily_avg_price = filtered_data.groupby(filtered_data['date'].dt.date)['price'].mean()\n",
    "\n",
    "item_state = None\n",
    "item_name = filtered_data.iloc[0]['item']\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(daily_avg_price.index, daily_avg_price.values)\n",
    "\n",
    "if item_state is not None:\n",
    "    plt.title(f'Daily Average Price of {item_name} in {item_state}')\n",
    "else:\n",
    "    plt.title(f'Daily Average Price of {item_name} in Malaysia')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Average Price')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
